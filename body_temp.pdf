Supplementary Material for: Pareto Domain
Adaptation

Fangrui Lv,1,∗

Jian Liang,2,∗ Kaixiong Gong,1 Shuang Li,1,†

Chi Harold Liu,1 Han Li,2 Di Liu,2 Guoren Wang1

1 Beijing Institute of Technology, China

2Alibaba Group, China

1 {fangruilv,kxgong,shuangli,wanggrbit}@bit.edu.cn, liuchi02@gmail.com
2 {xuelang.lj,lihan.lh,wendi.ld}@alibaba-inc.com

1 Potential Negative Societal Impacts

Our work focuses on domain adaptation and attempts to properly handle the multiple objectives
optimization in it from a gradient-based perspective, which further enhance the performance of
adaptive models. This method exerts a positive inﬂuence on the society and the community, saves the
cost and time of data annotation, boosts the reusability of knowledge across domains, and greatly
improves the efﬁciency. However, this work suffers from some negative consequences, which is
worthy of further research and exploration. Speciﬁcally, more jobs of classiﬁcation or target detection
for rare or variable conditions may be cancelled. Besides, we should be cautious of the result of the
failure of the system, which could render people believe that classiﬁcation was unbiased. Still, it
might be not, which might be misleading, e.g., when using the system in an unlabeled domain.

2 Experimental Details

We evaluate our method on cross-domain image classiﬁcation and semantic segmentation datasets.
For the former, we conduct experiments on Ofﬁce-31, VisDA-2017 and Ofﬁce-Home datasets. For
the latter, we conduct experiments on GTA5 and Cityscapes. We directly quote the results from
original papers if the experimental settings are the same. In addition, we report the average result of
three random experiments.

2.1 Experiment on image classiﬁcation

Network architectures We adopt the ResNet-50 and ResNet-101 [7] model pre-trained on ImageNet
[9] as the backbone network for classiﬁcation tasks, and replace the last fully connected layer with a
bottleneck layer to speed up the experiments [6, 14]. The architecture of classiﬁer is simply a single
fully connected layers with random initialization attached to the bottleneck layer. And the domain
discriminator is composed of three fully connected layers, each followed by a BatchNormalize layer
and a Relu activation function. Admittedly, the choice for the classiﬁer and discriminator is arbitrary
and better adaptation performance may be obtained if this part of the architecture is tuned.

Training details We ﬁne-tune from ImageNet pre-trained models and train other layers from the
scratch with learning rate 10 times that of the feature generator layers. We adopt Stochastic Gradient
Descent optimizer (SGD) [1] with learning rate 0.003, momentum 0.9 and weight decay 1 × 10−4.
Besides, we adopt the annealing procedure mentioned in [14] to schedule the learning rate. All
experiments run on a single NVIDIA RTX 3090 GPU for training.

35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia.

Method
ResNet [7]
DAN [13]
JADA [10]
BNM [4]
TAT [12]
GSP [19]
DANN [6]
+BSP [3]
+MCC [8]
+ParetoDA
CDAN [14]
+BSP [3]
+MCC [8]
+ParetoDA
MDD [20]
+ParetoDA

Table 1: Classiﬁcation accuracy (%) on Ofﬁce-31 (ResNet-50).
A:W
68.4
80.5
90.5
91.5
92.5
92.9
82.0
93.0
95.6
95.5 ± 0.1
94.1
93.3
94.7
95.0 ± 0.2
93.5
95.4 ± 0.2

W:D
99.3
99.6
100.0
100.0
100.0
99.8
99.1
100.0
99.3
100.0 ± 0.0
100.0
100.0
100.0
100.0 ±0.0
100.0
100.0 ± 0.0

A:D
68.9
78.6
88.2
90.3
93.2
94.5
79.7
90.0
93.8
93.8 ±0.2
92.9
93.0
95.0
95.4 ± 0.2
94.5
94.4 ± 0.3

D:W
62.5
63.6
70.9
70.9
73.1
75.9
68.2
71.9
74.0
76.7±0.2
71.0
73.6
73.0
77.6 ± 0.3
74.6
76.2 ± 0.4

D:W
96.7
97.1
97.5
98.5
99.3
98.7
96.9
98.0
98.6
98.7 ± 0.3
98.6
98.2
98.6
98.9±0.1
98.4
98.9 ± 0.2

W:A
60.7
62.8
70.6
71.6
72.1
74.9
67.4
73.0
75.0
76.3 ±0.3
69.3
72.6
73.6
75.7 ± 0.2
72.2
75.8 ± 0.2

Avg
76.1
80.4
86.1
87.1
88.4
89.5
82.2
87.7
89.4
90.2
87.7
88.5
89.2
90.4
88.9
90.1

Method
ResNet [7]
DAN [13]
TAT [12]
TPN [16]
BNM [4]
MDD [20]
GSP [19]
DANN [6]
+BSP [3]
+MetaAlign [18]
+ParetoDA
CDAN [14]
+BSP [3]
+MetaAlign [18]
+ParetoDA

Ar:Pr
50.0
57.0
69.5
71.2
73.9
73.7
75.5
59.3
68.3
69.5

Ar:Cl
34.9
43.6
51.6
51.2
52.3
54.9
56.8
45.6
51.4
48.6

Ar:Rw
58.0
67.9
75.4
76.0
80.0
77.8
78.9
70.1
75.9
76.0

Table 2: Accuracy(%) on Ofﬁce-Home for unsupervised DA (ResNet-50).
Pr:Rw Rw:Ar Rw:Cl
41.2
53.9
60.4
51.5
63.1
67.7
56.6
70.9
76.8
53.4
70.9
76.5
53.6
70.5
79.7
60.2
72.5
78.1
54.2
73.3
79.9
51.8
63.2
68.5
57.1
70.4
75.8
50.8
68.5
75.3

Rw:Pr Avg.
46.1
59.9
56.3
74.3
65.8
81.6
66.2
80.4
67.9
82.2
68.1
82.3
68.4
83.2
57.6
76.8
64.9
80.6
63.3
80.1
55.2 ± 0.4 74.4 ± 0.3 79.0 ± 0.4 61.9 ± 0.6 72.4 ± 0.5 72.9 ± 0.3 62.1 ± 0.4 55.8 ± 0.5 81.1 ± 0.4 74.4 ± 0.6 61.1 ± 0.5 82.4 ± 0.4 69.4
65.8
66.3
67.8
56.8 ± 0.3 75.9 ± 0.4 80.5 ± 0.2 64.4 ± 0.5 73.5 ± 0.3 73.7 ± 0.6 65.6 ± 0.4 55.2 ± 0.5 81.3 ± 0.2 75.2 ± 0.5 61.1 ± 0.4 83.9 ± 0.3 70.6

Cl:Rw
46.2
60.4
68.6
72.8
74.9
71.8
74.9
60.9
68.8
68.3

Cl:Ar
37.4
45.8
59.4
65.1
63.3
60.0
61.3
47.0
56.0
58.1

Pr:Ar
38.5
44.0
59.5
55.4
61.7
61.2
61.3
46.1
57.0
54.9

Cl:Pr
41.9
56.5
69.5
72.9
72.9
71.4
69.4
58.5
67.8
65.7

Pr:Cl
31.2
43.6
50.5
48.9
49.5
53.6
52.6
43.7
49.6
44.4

57.4
58.6
58.7

57.6
58.0
61.5

70.0
70.3
70.0

70.0
70.2
70.0

70.6
68.6
70.5

56.7
59.3
61.0

81.6
81.9
81.7

77.3
77.6
78.5

50.7
52.0
55.2

50.9
50.2
55.7

70.9
72.2
73.3

76.0
76.1
77.6

2.2 Experiment on semantic segmentation

Network architectures We leverage the DeepLab-v2 [2] framework with the pre-trained ResNet-101
model as the base feature extractor for segmentation task. To better capture the scene context, Atrous
Spatial Pyramid Pooling (ASPP) is used for classiﬁer and applied on the conv5 feature outputs. We
ﬁx the sampling rates as {6, 12, 18, 24} following [17] and modify the stride and dilation rate of the
last layers to produce denser feature maps with larger ﬁeld-of-views.

Training details For evaluation metrics, we report pre-class intersection-over-union (IoU) and mean
IoU over all classes. We use the evaluation code released along with the Cityscapes dataset, which
T P +F P +F N [5], where T P , F P ,
calculates the PASCAL VOC intersection-over-union, i.e, IoU =
F N are the amount of true positive, false positive and false negative pixels, respectively, determined
over the whole test set.

T P

3 Experimental Results with Error Bars

For the sake of objective, we run all the experiments multiple times with random seed. We report the
average results in the main body of paper for elegant, and show the complete results with error bars
in the form of mean±std below (Table. 1,2).

2

4 Derivation and Proofs

4.1 Proof for Theorem 1

Proof. If LV al = 0, then its gradient is also a zero vector: ˆgv = 0. This means J is empty. As a
result, I(J (cid:54)= ∅) = 0 and all the constraints of Eq. (6) becomes

(d∗)T gj ≥ 0, ∀j ∈ {1, 2, 3}.

(1)

Then d∗ becomes a descent direction.
On the other hand, we consider the case in that LV al > 0. Since γ∗ = (d∗)T ˆgv, then γ∗ > 0 means
(d∗)T ˆgv > 0. Whereas if γ∗ = (d∗)T ˆgv = (Gw∗)T ˆgv ≤ 0, since Gw∗ is the maximum of the
convex combination of the columns in G, it means that there is no gradient gj, j ∈ {1, 2, 3}, for
which gT
j ˆgv > 0. As a result, J is empty and I(J (cid:54)= ∅) = 0. This is similar to the case of LV al = 0.
So d∗ becomes a descent direction.

4.2 Derivations for Eq. (4)

Our derivations follow a standard Expectation-Maximization process. Eq. (3) is actually the E-step
to estimate the hidden variable, class label, on the target domain. The detailed derivation is in the
following.

p(y = c | z = d, x, θ, φc) =

(cid:80)

p(y = c, z = d | x, θ, φc)
p(z = d | x, θ, φc)
p(y = c, z = d | x, θ, φc)
c(cid:48) p(y = c(cid:48), z = d | x, θ, φc)
p(z = d | y = c, x, θ, φc)p(y = c | x, θ, φc)
c(cid:48) p(z = d | y = c(cid:48), x, θ, φc)p(y = c(cid:48) | x, θ, φc)
p(z = d | x, vc)p(y = c | x, θ, φc)
c(cid:48) p(z = d | x, vc(cid:48) )p(y = c(cid:48) | x, θ, φc)

= ρc|d.

(cid:80)

(cid:80)

=

=

=

And Eq. (4) is a part of the M-step.

For the M-step, we maximize the joint likelihood,

p(y = c, z = d | x, θ, φc)I(y=c,z=d)

p(z = d | y = c, x, θ, φc)I(z=d)p(y = c | x, θ, φc)I(y=c)

p(z = d | x, vc)I(z=d)p(y = c | x, θ, φc)I(y=c).

Then the log likelihood is

I(z = d)I(y = c) log[p(z = d | x, vc)p(y = c | x, θ, φc)].

For target domains where class labels are not available, we replace I(y = c) with the conditional
estimation ρc|d. Then we have the ﬁnal log likelihood:

I(z = d)sc|d log[p(z = d | x, vc)p(y = c | x, θ, φc)],

where sc|d = I(y = c) is for the source domain, and sc|d = ρc|d is for the target domain.

3

D
(cid:89)

C
(cid:89)

d=1

c=1

=

=

D
(cid:89)

C
(cid:89)

d=1

c=1

D
(cid:89)

C
(cid:89)

d=1

c=1

D
(cid:88)

C
(cid:88)

d=1

c=1

D
(cid:88)

C
(cid:88)

d=1

c=1

We decompose the ﬁnal log likelihood as

I(z = d)sc|d log p(z = d | x, vc) +

I(z = d)sc|d log p(y = c | x, θ, φc)

D
(cid:88)

C
(cid:88)

d=1

c=1

C
(cid:88)

D
(cid:88)

c=1

d=1

D
(cid:88)

C
(cid:88)

d=1

c=1

D
(cid:88)

d=1

C
(cid:88)

c=1

=

sc|dI(z = d) log p(z = d | x, vc) +

I(z = d)

sc|d log p(y = c | x, θ, φc),

where the ﬁrst term is Eq. (4) and learns domain discrimination for each class with a weighted loss
(the weight is sc|d), and the second term learns classiﬁcation for each domain. For the source domain,
the class labels are hard. Whereas for the target domain, the class labels are soft.

4.3 Existence Guarantee for Pareto optimal solution

Similar as in [11], we provide a theoretical guarantee for the existence of a Pareto critical (also named
as local Pareto optimal in [15]) solution of our method, where a solution is called Pareto critical if no
other solution in its neighborhood can dominate this solution. Speciﬁcally, we show by Theorem 1
below that our method will optimize until the solution is Pareto critical and satisﬁes LV al = 0.
Theorem 1. Let ˆθ be the ﬁnal output model parameters of our method. Let w∗ be the solution of the
problem in Eq. (6) based on ˆθ, and d∗ = Gw∗ be the resulted update direction. We have:

• if ˆθ is not Pareto critical, then d∗ (cid:54)= 0 ∈ Rd;

• if ˆθ is Pareto critical, we further consider two cases:

– If LV al = 0, then d∗ = 0 ∈ Rd or (d∗)T G = 0 ∈ R3. In either case, the update is

meaningless and will halt.

– If LV al > 0, assuming the gradient of LT is consistent with the gradient of LV al, i.e.,

3 ˆgv > 0, then d∗ (cid:54)= 0 ∈ Rd.
gT
3 ˆgv > 0 for a Pareto critical ˆθ is reasonable, because
Note that the assumption that gT
when ˆθ is Pareto critical, the model is usually well-trained, and g3, ˆgv are gradients
of the same loss on i.i.d sampled two datasets from the target domain. Then it is
reasonable to assume the gradients are consistent.

The proof of Theorem 1 is as following:

Proof.

• If ˆθ is not Pareto critical, we suppose d∗ = Gw∗ = 0 ∈ Rd, where w∗
j > 0 for all j ∈
{1,2,3}. Since ˆθ is not Pareto critical, there exists a d(cid:48) (cid:54)= 0 ∈ Rd that satisﬁes (d(cid:48))T gj > 0,
for some j ∈ {1,2,3}; and (d(cid:48))T gi ≥ 0, for other i ∈ {1,2,3} and i (cid:54)= j. Since Gw∗ =
0, then w∗
j gj) > 0
and (d(cid:48))T ((cid:80)
i gi) < 0 is not possible because
(d(cid:48))T gi ≥ 0, for i ∈ 1,2,3 and i (cid:54)= j and w∗
i > 0 for all i ∈ 1,2,3, which generates a
contradiction for d∗ = 0 ∈ Rd.

i gi . Also, because (d(cid:48))T gj > 0, then (d(cid:48))T (w∗
i(cid:54)=j w∗

i gi) < 0. However, (d(cid:48))T ((cid:80)

j gj = − (cid:80)
i(cid:54)=j w∗

i(cid:54)=j w∗

• If ˆθ is Pareto critical, we consider two cases.

– If LV al = 0, then from Theorem 1 we know that d∗ becomes a descent direction, i.e.,
(d∗)T gj ≥ 0, ∀j ∈ 1,2,3. Since ˆθ is Pareto critical, then there does not exist j ∈
1,2,3 such that (d∗)T gj > 0. Then(d∗)T gj = 0, ∀j ∈ 1,2,3. Thus, we either have
d∗ = 0 ∈ Rd or just (d∗)T G = 0 ∈ R3.

– Consider the second case, LV al > 0, then ˆgv (cid:54)= 0 ∈ Rd. Given the assumption that
3 ˆgv > 0, then g3 (cid:54)= 0 ∈ Rd. Then w(cid:48) can be [0, 0, 1] and γ(cid:48) = (Gw(cid:48))T ˆgv =
gT
3 ˆgv > 0. Therefore, the maximized γ∗ ≥ γ(cid:48) > 0, then from Theorem 1 we know
gT
that (d∗)T ˆgv > 0, which means d∗ (cid:54)= 0 ∈ Rd.

4

In summary, we can obtain a Pareto critical solution with simple iterative gradient-based update rule
θt+1 = θt + ηd.

References

pages 177–186, 2010.

[1] L. Bottou. Large-scale machine learning with stochastic gradient descent. In COMPSTAT,

[2] L. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. Deeplab: Semantic image
segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. TPAMI,
40(4):834–848, 2018.

[3] X. Chen, S. Wang, M. Long, and J. Wang. Transferability vs. discriminability: Batch spectral

penalization for adversarial domain adaptation. In ICML, pages 1081–1090, 2019.

[4] S. Cui, S. Wang, J. Zhuo, L. Li, Q. Huang, and T. Qi. Towards discriminability and diversity:
Batch nuclear-norm maximization under label insufﬁcient situations. CoRR, abs/2003.12237,
2020.

[5] M. Everingham, S. M. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The

pascal visual object classes challenge: A retrospective. IJCV, 111(1):98–136, 2015.

[6] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation by backpropagation. In ICML,

pages 1180–1189, 2015.

pages 770–778, 2016.

[7] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR,

[8] Y. Jin, X. Wang, M. Long, and J. Wang. Minimum class confusion for versatile domain

adaptation. In ECCV, volume 12366, pages 464–480, 2020.

[9] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classiﬁcation with deep convolutional

neural networks. In NeurIPS, pages 1097–1105, 2012.

[10] S. Li, C. H. Liu, B. Xie, L. Su, Z. Ding, and G. Huang. Joint adversarial domain adaptation. In

ACM MM, pages 729–737, 2019.

[11] X. Lin, H. Zhen, Z. Li, Q. Zhang, and S. Kwong. Pareto multi-task learning. In NeurIPS, pages

12037–12047, 2019.

[12] H. Liu, M. Long, J. Wang, and M. I. Jordan. Transferable adversarial training: A general

approach to adapting deep classiﬁers. In ICML, pages 4013–4022, 2019.

[13] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with deep adaptation

networks. In ICML, pages 97–105, 2015.

[14] M. Long, Z. Cao, J. Wang, and M. I. Jordan. Conditional adversarial domain adaptation. In

NeurIPS, pages 1647–1657, 2018.

[15] D. Mahapatra and V. Rajan. Multi-task learning with user preferences: Gradient descent with

controlled ascent in pareto optimization. In ICML, pages 6597–6607, 2020.

[16] Y. Pan, T. Yao, Y. Li, Y. Wang, C.-W. Ngo, and T. Mei. Transferrable prototypical networks for

unsupervised domain adaptation. In CVPR, June 2019.

[17] Y. Tsai, W. Hung, S. Schulter, K. Sohn, M. Yang, and M. Chandraker. Learning to adapt
structured output space for semantic segmentation. In CVPR, pages 7472–7481, 2018.

[18] G. Wei, C. Lan, W. Zeng, and Z. Chen. Metaalign: Coordinating domain alignment and

classiﬁcation for unsupervised domain adaptation. CoRR, abs/2103.13575, 2021.

5

[19] H. Xia and Z. Ding. Structure preserving generative cross-domain learning. In CVPR, pages

4363–4372, 2020.

[20] Y. Zhang, T. Liu, M. Long, and M. Jordan. Bridging theory and algorithm for domain adaptation.

In ICML, pages 7404–7413, 2019.

Checklist

1. For all authors...

(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s

contributions and scope? [Yes]

(b) Did you describe the limitations of your work? [Yes] See section ??
(c) Did you discuss any potential negative societal impacts of your work? [Yes] See

appendix in supplementary materials.

(d) Have you read the ethics review guidelines and ensured that your paper conforms to

them? [Yes]

2. If you are including theoretical results...

in supplementary materials

supplementary materials

3. If you ran experiments...

(a) Did you state the full set of assumptions of all theoretical results? [Yes] See appendix

(b) Did you include complete proofs of all theoretical results? [Yes] See appendix in

(a) Did you include the code, data, and instructions needed to reproduce the main experi-
mental results (either in the supplemental material or as a URL)? [Yes] See section ??
and the appendix in supplementary materials

(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
were chosen)? [Yes] See section ?? and the appendix in supplementary materials
(c) Did you report error bars (e.g., with respect to the random seed after running experi-

ments multiple times)? [Yes] See appendix in supplementary materials

(d) Did you include the total amount of compute and the type of resources used (e.g., type
of GPUs, internal cluster, or cloud provider)? [Yes] See the appendix in supplementary
materials

4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
(a) If your work uses existing assets, did you cite the creators? [Yes] See section ??
(b) Did you mention the license of the assets? [No] The code and the data are public.
(c) Did you include any new assets either in the supplemental material or as a URL? [No]
(d) Did you discuss whether and how consent was obtained from people whose data you’re

using/curating? [No] The code and the data are public.

(e) Did you discuss whether the data you are using/curating contains personally identiﬁable

information or offensive content? [No] The code and the data are public.

5. If you used crowdsourcing or conducted research with human subjects...

(a) Did you include the full text of instructions given to participants and screenshots, if

applicable? [N/A]

(b) Did you describe any potential participant risks, with links to Institutional Review

Board (IRB) approvals, if applicable? [N/A]

(c) Did you include the estimated hourly wage paid to participants and the total amount

spent on participant compensation? [N/A]

6

